# Authors: Jonas Schluter <jonas.schluter@nyulangone.org>, Grant Hussey <grant.hussey@nyulangone.org>
# License: BSD 3 clause # Which license?

__author__ = ["Jonas Schluter", "Grant Hussey"]
__copyright__ = "Copyright 2020, MIT License"

import logging
import os
import sys
import warnings
from pathlib import Path

import matplotlib as mpl
import numpy as np
import pandas as pd
import scipy.spatial.distance as ssd
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from umap import UMAP

import humap.tools as tools
import humap.visualizations as viz


class Defaults:
    distance_metrics = [
        "braycurtis",
        "canberra",
        "chebyshev",
        "cityblock",
        "correlation",
        "cosine",
        "dice",
        "euclidean",
        "hamming",
        "jaccard",
        "jensenshannon",
        "kulczynski1",
        "mahalanobis",
        "matching",
        "minkowski",
        "rogerstanimoto",
        "russellrao",
        "seuclidean",
        "sokalmichener",
        "sokalsneath",
        "sqeuclidean",
        "yule",
    ]


class Humap:
    """Humap object for running hUMAP algorithm"""

    def __init__(
        self,
        agg_levels=None,
        weights=None,
        data=None,
        hierarchy=None,
        name=None,
        random_state=42,
    ):

        self.random_state = random_state

        if isinstance(data, pd.DataFrame):
            self.data = data
        elif isinstance(data, np.ndarray):
            self.data = pd.DataFrame(data)
        elif Path(data).is_file():
            self.data = pd.read_csv(data, index_col=0)

        if isinstance(hierarchy, pd.DataFrame):
            self.hierarchy = hierarchy
        elif isinstance(hierarchy, np.ndarray):
            self.hierarchy = pd.DataFrame(hierarchy)
        elif Path(hierarchy).is_file():
            self.hierarchy = pd.read_csv(hierarchy, index_col=0)

        self.name = name

        if agg_levels is None:
            self.agg_levels = self.hierarchy.columns[[0, 1]]
        else:
            self.agg_levels = agg_levels

        if weights is None:
            self.weights = [1] * len(agg_levels)
        else:
            if len(weights) != len(agg_levels):
                raise Exception(
                    "Length of `weights` parameter must match length of `agg_levels` parameter"
                )
            else:
                self.weights = weights

        self.rng = np.random.RandomState(seed=self.random_state)

    @property
    def _embedded_csv_name(self):
        """Filename for saving self.embedded to a csv file. Uses self.name if available."""
        if isinstance(self.name, str):
            return "_".join([self.name, "embedded.csv"])
        else:
            return "embedded.csv"

    @property
    def _embedded_pickle_name(self):
        """Filename for saving self to a pickle. Uses self.name if available."""
        if isinstance(self.name, str):
            return "_".join([self.name, "humap_pickle.pickle"])
        else:
            return "humap_pickle.pickle"

    @property
    def humap1(self):
        """Get a label for first dimension of hUMAP embedded space"""
        first_letters = [agg_level[0] for agg_level in self.agg_levels]
        initials = "".join(first_letters)
        return "humap-{}-1".format(initials)

    @property
    def humap2(self):
        """Get a label for second dimension of hUMAP embedded space"""
        first_letters = [agg_level[0] for agg_level in self.agg_levels]
        initials = "".join(first_letters)
        return "humap-{}-2".format(initials)

    @property
    def _is_transformed(self):
        """Returns True if Humap.transform_self() has been previously run"""

        if hasattr(self, "embedding"):
            if isinstance(self.embedding, np.ndarray):
                pass
            else:
                warnings.warn(
                    "humap.embedding is not an ndarray, something may be wrong"
                )

            return True
        else:
            return False

    @property
    def index(self):
        return self.data.index

    @property
    def df_embedding(self):
        """Creates a dataframe from the embedding generated by Humap.transform_self()"""
        if self._is_transformed:
            return pd.DataFrame(
                self.embedding,
                columns=[self.humap1, self.humap2],
                index=self.index,
            )
        else:
            raise AttributeError(
                "Please run Humap.transform_self() to generate your embedding"
            )

    @property
    def df_dominant_level(self):

        # DataFrame where each row is the maximum taxon corresponding to the
        # shared index in the column index_column
        df_dom_tax_per_sample = (
            pd.DataFrame(self.data.idxmax(axis="columns"), columns=["max_tax"])
            .reset_index()
            .set_index("max_tax")
        )

        # This is where a merge is done to add in the full taxonomical
        # data for each of the "max_tax" dominant taxon
        prelim_df_table = df_dom_tax_per_sample.merge(
            self.hierarchy, right_index=True, left_index=True
        )

        # all below here, I am cleaning the prelim_df_table for final return
        tax_hierarchy = prelim_df_table.columns[
            prelim_df_table.columns != "index_column"
        ]

        new_tax_hierarchy = [
            "dom_" + each_level.lower() for each_level in tax_hierarchy
        ]

        change_labels = dict(zip(tax_hierarchy, new_tax_hierarchy))

        df_final = prelim_df_table.rename(columns=change_labels)
        df_final.index.name = "max_tax"
        df_final = df_final.reset_index().set_index("index_column")

        return df_final

    @classmethod
    def from_pickle(cls, fp):
        import pickle

        try:
            with open(fp, "rb") as f:
                data = pickle.load(f)
        except Exception:
            warnings.warn("Something went wrong loading from pickle")
        else:
            warnings.warn("Successfully located pickle file")

        return data

    def to_pickle(self, outdir=".", name=None):

        import pickle

        if name is None:
            name = self._embedded_pickle_name

        with open(os.path.join(outdir, name), "wb") as f:
            pickle.dump(self, f)

        return self

    def agg_and_run_umap(self, distance_metric, neigh, min_dist, epochs):

        Xagg = generate_xagg(
            self.data,
            self.hierarchy,
            self.agg_levels,
            distance_metric,
            self.weights,
        )

        self = self.run_umap(Xagg, neigh, min_dist, epochs)

        return self

    def run_umap(self, Xagg, neigh, min_dist, epochs):

        self.humap = UMAP(
            n_neighbors=neigh,
            min_dist=min_dist,
            n_epochs=epochs,
            metric="precomputed",
            transform_seed=42,
            random_state=self.rng,
        ).fit(Xagg)

        return self

    def fit(self, distance_metric=None, Xagg=None, **kwargs):

        if "neigh" not in kwargs:
            warnings.warn(
                "Please set neigh parameter to approx. the size of individals in the dataset. See documentation."
            )
            neigh = 120 if len(self.data) > 120 else len(self.data) - 1
        else:
            neigh = kwargs["neigh"]

        if "min_dist" not in kwargs:
            warnings.warn("Setting min_dist to 0.05/sum(weights)")
            min_dist = 0.05 / np.sum(self.weights)
        else:
            min_dist = kwargs["min_dist"]

        if "epochs" not in kwargs:
            epochs = 5000 if neigh < 120 else (1000 if len(self.data) < 5000 else 1000)
            warnings.warn("Setting epochs to %d" % epochs)
        else:
            epochs = kwargs["epochs"]

        if Xagg is not None:
            # this means you're supplying Xagg

            self.run_umap(self, Xagg, neigh, min_dist, epochs)

        elif distance_metric == None:
            distance_metric = "braycurtis"

            self.agg_and_run_umap(distance_metric, neigh, min_dist, epochs)

        elif distance_metric in Defaults.distance_metrics:
            self.agg_and_run_umap(distance_metric, neigh, min_dist, epochs)

        else:
            raise ValueError(
                f"distance_metric must be 'precomputed' (supplying Xagg), None (for braycurtis), or one from {Defaults.distance_metrics}"
            )

    def transform(self, **kwargs):
        pass

    def fit_transform(self):
        self = self.fit()
        self = self.transform()
        return self


def generate_xagg(data, hierarchy, agg_levels, distance_metric, weights):
    """Generates a distance matrix aggregated on each designated taxon

    Args:
        data (Pandas df): Relative abundance df with row-wise compositional data, row: sample, columns: OTU/ASV label
        hierarchy (Pandas df): Row: OTU/ASV label, columns: hierarchy of hierarchy for that ASV/OTU
        agg_levels (list of str): Taxons to aggregate
        distance_metric (str): String to pass to ssd.cdist()
        weights (list of int): Weights of the non-ASV/OTU taxons

    Returns:
        pandas df: distance table, row and columns are sample ids
    """

    _X = data.copy()
    # remove columns that are always zero
    _X = _X.loc[:, (_X != 0).any(axis=0)]
    Xdist = ssd.cdist(_X, _X, distance_metric)
    Xdist = pd.DataFrame(Xdist, index=_X.index, columns=_X.index)

    for agg_level, weight in zip(agg_levels, weights):
        Xagg = tools.aggregate_at_taxlevel(_X, hierarchy, agg_level)
        Xagg = ssd.cdist(Xagg, Xagg, distance_metric)
        Xagg = pd.DataFrame(Xagg, index=_X.index, columns=_X.index)
        Xagg = Xagg * weight

        Xdist = Xdist + Xagg

    return Xdist
